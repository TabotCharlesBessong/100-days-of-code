{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'><img src='../Pierian_Data_Logo.png'/></a>\n",
    "___\n",
    "<center><em>Copyright by Pierian Data Inc.</em></center>\n",
    "<center><em>For more information, visit us at <a href='http://www.pieriandata.com'>www.pieriandata.com</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and Outputs\n",
    "\n",
    "**NOTE: Typically we will just be either reading csv files directly or using pandas-datareader to pull data from the web. Consider this lecture just a quick overview of what is possible with pandas (we won't be working with SQL or Excel files in this course)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input and Output\n",
    "\n",
    "This notebook is the reference code for getting input and output, pandas can read a variety of file types using its pd.read_ methods. Let's take a look at the most common data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the references here! \n",
    "\n",
    "**This is the best online resource for how to read/write to a variety of data sources!**\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\n",
    "\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"colwidths-given docutils\">\n",
    "<colgroup>\n",
    "<col width=\"12%\" />\n",
    "<col width=\"40%\" />\n",
    "<col width=\"24%\" />\n",
    "<col width=\"24%\" />\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">Format Type</th>\n",
    "<th class=\"head\">Data Description</th>\n",
    "<th class=\"head\">Reader</th>\n",
    "<th class=\"head\">Writer</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td>text</td>\n",
    "<td><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-read-csv-table\"><span class=\"std std-ref\">read_csv</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-store-in-csv\"><span class=\"std std-ref\">to_csv</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>text</td>\n",
    "<td><a class=\"reference external\" href=\"https://www.json.org/\">JSON</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-json-reader\"><span class=\"std std-ref\">read_json</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-json-writer\"><span class=\"std std-ref\">to_json</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>text</td>\n",
    "<td><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/HTML\">HTML</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-read-html\"><span class=\"std std-ref\">read_html</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-html\"><span class=\"std std-ref\">to_html</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>text</td>\n",
    "<td>Local clipboard</td>\n",
    "<td><a class=\"reference internal\" href=\"#io-clipboard\"><span class=\"std std-ref\">read_clipboard</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-clipboard\"><span class=\"std std-ref\">to_clipboard</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Microsoft_Excel\">MS Excel</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-excel-reader\"><span class=\"std std-ref\">read_excel</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-excel-writer\"><span class=\"std std-ref\">to_excel</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"http://www.opendocumentformat.org\">OpenDocument</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-ods\"><span class=\"std std-ref\">read_excel</span></a></td>\n",
    "<td>&#160;</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://support.hdfgroup.org/HDF5/whatishdf5.html\">HDF5 Format</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-hdf5\"><span class=\"std std-ref\">read_hdf</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-hdf5\"><span class=\"std std-ref\">to_hdf</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://github.com/wesm/feather\">Feather Format</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-feather\"><span class=\"std std-ref\">read_feather</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-feather\"><span class=\"std std-ref\">to_feather</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://parquet.apache.org/\">Parquet Format</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-parquet\"><span class=\"std std-ref\">read_parquet</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-parquet\"><span class=\"std std-ref\">to_parquet</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://msgpack.org/index.html\">Msgpack</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-msgpack\"><span class=\"std std-ref\">read_msgpack</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-msgpack\"><span class=\"std std-ref\">to_msgpack</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Stata\">Stata</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-stata-reader\"><span class=\"std std-ref\">read_stata</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-stata-writer\"><span class=\"std std-ref\">to_stata</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SAS_(software)\">SAS</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-sas-reader\"><span class=\"std std-ref\">read_sas</span></a></td>\n",
    "<td>&#160;</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>binary</td>\n",
    "<td><a class=\"reference external\" href=\"https://docs.python.org/3/library/pickle.html\">Python Pickle Format</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-pickle\"><span class=\"std std-ref\">read_pickle</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-pickle\"><span class=\"std std-ref\">to_pickle</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>SQL</td>\n",
    "<td><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SQL\">SQL</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-sql\"><span class=\"std std-ref\">read_sql</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-sql\"><span class=\"std std-ref\">to_sql</span></a></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td>SQL</td>\n",
    "<td><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/BigQuery\">Google Big Query</a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-bigquery\"><span class=\"std std-ref\">read_gbq</span></a></td>\n",
    "<td><a class=\"reference internal\" href=\"#io-bigquery\"><span class=\"std std-ref\">to_gbq</span></a></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in a  CSV\n",
    "Comma Separated Values files are text files that use commas as field delimeters.<br>\n",
    "Unless you're running the virtual environment included with the course, you may need to install <tt>xlrd</tt> and <tt>openpyxl</tt>.<br>\n",
    "In your terminal/command prompt run:\n",
    "\n",
    "    conda install xlrd\n",
    "    conda install openpyxl\n",
    "\n",
    "Then restart Jupyter Notebook.\n",
    "(or use pip install if you aren't using the Anaconda Distribution)\n",
    "\n",
    "## Understanding File Paths\n",
    "\n",
    "You have two options when reading a file with pandas:\n",
    "\n",
    "1. If your .py file or .ipynb notebook is located in the **exact** same folder location as the .csv file you want to read, simply pass in the file name as a string, for example:\n",
    "    \n",
    "df = pd.read_csv('./data/some_file.csv')\n",
    "df\n",
    "        \n",
    "2. Pass in the entire file path if you are located in a different directory. The file path must be 100% correct in order for this to work. For example:\n",
    "\n",
    "        <!-- df = pd.read_csv(\"C:\\\\Users\\\\myself\\\\files\\\\some_file.csv\") -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print your current directory file path with pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the files in your current directory with ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### NOTE! Common confusion point! Take note that all read input methods are called directly from pandas with pd.read_  , all output methods are called directly off the dataframe with df.to_\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/example.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Output\n",
    "\n",
    "Set index=False if you do not want to save the index , otherwise it will add a new column to the .csv file that includes your index and call it \"Unnamed: 0\" if your index did not have a name. If you do want to save your index, simply set it to True (the default value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/new_file1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML\n",
    "\n",
    "Pandas can read table tabs off of HTML. This only works if your firewall isn't blocking pandas from accessing the internet!\n",
    "\n",
    "Unless you're running the virtual environment included with the course, you may need to install <tt>lxml</tt>, <tt>htmllib5</tt>, and <tt>BeautifulSoup4</tt>.<br>\n",
    "In your terminal/command prompt run:\n",
    "\n",
    "    conda install lxml\n",
    "    \n",
    "    or\n",
    "    \n",
    "    pip install lxml\n",
    "    \n",
    "Then restart Jupyter Notebook (you may need to restart your computer).\n",
    "(or use pip install if you aren't using the Anaconda Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read_html\n",
    "\n",
    "### HTML Input\n",
    "\n",
    "Pandas read_html function will read tables off of a webpage and return a list of DataFrame objects. NOTE: This only works with well defined <table> objects in the html on the page, this can not magically read in tables that are images on a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html('https://en.wikipedia.org/wiki/World_population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(tables) #tables\n",
    "# tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Not Useful Tables\n",
    "Pandas found 26 tables on that page. Some are not useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables that need formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some will be misaligned, meaning you need to do extra work to fix the columns and rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pop = tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pop = world_pop['World population (millions, UN estimates)[14]'].drop('#',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pop.columns = ['Countries', '2000', '2015', '2030 Est.']\n",
    "world_pop = world_pop.drop(11,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables that are intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to html Output\n",
    "\n",
    "If you are working on a website and want to quickly output the .html file, you can use to_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html('simple.html',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read_html** is not perfect, but its quite powerful for such a simple method call!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel Files\n",
    "\n",
    "Pandas can read in basic excel files (it will get errors if there are macros or extensive formulas relying on outside excel files), in general, pandas can only grab the raw information from an .excel file.\n",
    "\n",
    "#### NOTE: Requires the openpyxl and xlrd library! Its provided for you in our environment, or simply install with:\n",
    "\n",
    "    pip install openpyxl\n",
    "    pip install xlrd\n",
    "    \n",
    "Heavy excel users may want to check out this website: https://www.python-excel.org/\n",
    "\n",
    "You can think of an excel file as a Workbook containin sheets, which for pandas means each sheet can be a DataFrame.\n",
    "\n",
    "## Excel file input with read_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('my_excel_file.xlsx',sheet_name='First_Sheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if you don't know the sheet name? Or want to run a for loop for certain sheet names? Or want every sheet?\n",
    "\n",
    "Several ways to do this: https://stackoverflow.com/questions/17977540/pandas-looking-up-the-list-of-sheets-in-an-excel-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of sheet_names\n",
    "pd.ExcelFile('my_excel_file.xlsx').sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab all sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sheets = pd.read_excel('my_excel_file.xlsx',sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(excel_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sheets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_sheets['First_Sheet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('example.xlsx',sheet_name='First_Sheet',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Connections\n",
    "\n",
    "#### NOTE: Highly recommend you explore specific libraries for your specific SQL Engine. Simple search for your database+python in Google and the top results should hopefully include an API.\n",
    "\n",
    "* [MySQL](https://www.google.com/search?q=mysql+python)\n",
    "* [PostgreSQL](https://www.google.com/search?q=postgresql+python)\n",
    "* [MS SQL Server](https://www.google.com/search?q=MSSQLserver+python)\n",
    "* [Orcale](https://www.google.com/search?q=oracle+python)\n",
    "* [MongoDB](https://www.google.com/search?q=mongodb+python)\n",
    "\n",
    "Let's review pandas capabilities by using SQLite, which comes built in with Python.\n",
    "\n",
    "## Example SQL Database (temporary in your RAM)\n",
    "\n",
    "You will need to install sqlalchemy with:\n",
    "\n",
    "    pip install sqlalchemy\n",
    "    \n",
    "to follow along. To understand how to make a connection to your own database, make sure to review: https://docs.sqlalchemy.org/en/13/core/connections.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_db = create_engine('sqlite:///:memory:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = tables[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.to_sql(name='populations',con=temp_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in an entire table\n",
    "pd.read_sql(sql='populations',con=temp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in with a SQL Query\n",
    "pd.read_sql_query(sql=\"SELECT Country FROM populations\",con=temp_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to generalize pandas and SQL, due to a wide array of issues, including permissions,security, online access, varying SQL engines, etc... Use these ideas as a starting off point, and you will most likely need to do your own research for your own situation."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e5eff28e1fe8eaff1ed87bdef7087dd0b80ab54a3ac8a2e96109ce025688be7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
